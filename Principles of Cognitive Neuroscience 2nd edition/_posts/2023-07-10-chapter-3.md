---
layout: post
title: 'Chapter 3: Sensory Systems and Perception: Vision'
---

For humans, the major sensory modalities are vision, audition, somatic sensation (touch pressure pain), olfaction (smell), and gustation (taste).

> **Prosopagnosia**
>
> Prosopagnosia is a deficiency in recognising faces. Following damage to the inferior temporal cortex typically on the right, patients are often unable to identify familiar faces. Recently, imaging and electrophysiological recordings confirmed that the ITC particularly the fusiform gyrus, mediates face recognition. 

> **Synesthesia**
>
>In synesthesia, individuals conflate experiences in one sensory domain with those in another. Its best understood expression is in individuals who see specific numerals, letters, or similar shapes printed in black and white as being differently colored (color-graphemic synesthesia). Other synesthesias include experiencing colors in response to musical notes and tastes elicited by certain words or numerals. 
>
>The reality of synesthesia in psychophysical studies (better reaction time in picking different letters, Stroop effect with the colors and letters). fMRI data show that synesthesia happens at the level of cerebral cortex. The most plausible explanation is aberrant wiring during early development. 

## The Initiation of Vision

The events that lead from stimuli to perception begin with the pre-neural elements of the eye that collect and filter light energy in the environment. These elements are the cornea, lens, and ocular media that focus and filter light before it reaches the retina. The first step that entails the nervous system is the transformation of light energy into neural signals by specialized receptor cells. 

Two types of receptor cells in the retina: rods and cones, responsible for low levels and high intensities of lights respectively. 

Sensory adaptation is the continual resetting of sensitivity according to ambient conditions. Adaptation is to ensure that sensory processing occurs with maximum efficiency. The need for resetting is because environmental range is large but firing rate of visual neurons is slow. Firing rate conveys stimulus intensity, and has a maximum of a few hundred action potentials per second. The intensity of the system is continually adapted to match different ongoing levels of light intensity in the environment. (Here sensory adaptation refers to mechanisms in the retina cells, not in the nervous system). 

Another property of the visual system is acuity. Acuity is different from sensitivity to intensity. Acuity measures the fineness of discrimination, as in distinguisching two nearby points. Visual acuity depends on the different distribution of receptor cells across the retina. Human visual acuity falls as a function of eccentricity (visual angle away from the line of sight). Less acuity outside of the central retina means that we must frequently move our eyes and the direction of gaze to different positions in visual space. Such eye movements are called saccades. 

## Subcortical Visual Processing

The first stage of central processing takes place in the five layers of the retina. This information converges onto retinal ganglion cells whose axons leave the retina via the optic nerve, the first component of the primary visual pathway. The pathway conveys the info in light stimuli that we end up perceiving as visual scenes. Retinal circuitry modulates the information that is eventually sent forward by retinal ganglion cells. 

![primary-visual-pathway](/img/principles-of-neuroscience/primary-visual-pathway.png)

The major target of the retina ganglion cells is the dorsal lateral geniculate nucleus in the thalamus. The lateral geniculate consists of two magnocellular system layers with dense large neurons and four parvocellular system layers with smaller neurons. 

The smaller P ganglion and the related parvocellular neurons in the lateral geniculate nucleus are concerned primarily with the spatial detail underlying the perception of form and brightness and color. The larger M ganglion cells and the magnocellular neurons they innervate process info about changes in stimuli that lead to motion perception. 

Neurons in both the magno and parvo layers are extensively innervated by axons descending from the cortex and other brain regions as well as those arising from retinal ganglion cells. 

## Cortical Visual Processing

The target of the lateral geniculate neurons is the primary visual cortex, aka the striate cortex or V1. The neurons in layer 4 receive the axons from neurons in the thalamus, while neurons in layers 1 and 5 of the primary visual cortex project to extrastriate visual cortical areas in the occipital parietal and temporal lobes, as well as back to the thalamus. The extrastriate cortex is generatlly considered a component of the cortical association areas (everything that is not primarily sensory or motor). 

![cytoarchitecture](/img/principles-of-neuroscience/cytoarchitecture.jpg)

The cortical association areas integrate the qualities of a given modality as well as information from other sensory modalities and from brain regions carrying out other functions, the processing carried out by the association cortices is often referred to as higher-order. The extrastriate visual cortical areas tend to process one or more of the qualities that define visual perception. E.g., V4 is important for processing info about color, and MT (middle temporal) and MST (middle superior temporal) are important for motion percepts. 

![visual-cortices](/img/principles-of-neuroscience/visual-cortices.png)
https://neurotorium.org/tool/brain-atlas/

Anatomical flow of different information streams. Extrastriate cortical areas are organized into two largely separate pathways that feed infor into the temporal and parietal lobes respectively. The ventral stream (the "what" pathway) leads from the visual cortex to the inferior part of the temporal lobe. This pathway appears to be responsible for high-resolution form vision and object recognition. The dorsal stream (the "where" pathway) leads from the striate cortex and other visual areas into the parietal lobe, and is responsible for spatial aspects of vision e.g. motion and positional relationships. Thus, the temporal lobe tends to exhibit properties that are important for object recognition e.g. selectivity for shape, color, texture. Neurons in the dorsal stream show selectivity for direction and speed of movement. (However recent evidence shows cross talk between these broadly defined sensory pathways.)

Info from a specific sensation must be integrated with info being processed by the other sensory systems in the higher-order processing areas to improve efficacy. E.g. vision affects audition and vice versa, McGurk effect. 

## Other Key Characteristics of the Visual Cortex

### Topography

The organization of the receptors in the retina is reflected in the corresponding regions of both the thalamus and the visual cortex. Topography is particularly apparent in the primary sensory cortices especially vision and somatosensory. The topography of the retina and the topography of the retina image is reestablished in both the thalamus and the cortex. The reason for the topographical layout of the primary visual system is unclear, it's likely that topography is mainly to do with minimizing neuronal wiring. 

### Cortical magnification

The size of each unit area of the retinal surface is disproportionately represented at the level of the cortex. A square degree of visual space in the fovea is represented by much more cortical area than the same unit area in the peripheral retina (cortical magnification). The idea that more complex neural processing requires more cortical or subcortical space is another general principle in the organization of sensory systems. 

### Cortical modularity

Primary and some secondary visual cortical areas are organised in iterated groups of neurons with similar functional properties. Each of these iterated units consists of hundreds or thousands of nerve cells, and together they are cortical modules or cortical columns. 

Despite highly regular structure, the function of cortical columns remains unclear. Little cross-species similarity in cortical columns. Many regions don't show columns. No clear rationale of such columns. 

### Visual receptive fields

The receptive field of a visual neuron is defined as the region of the retina that, when stimulated, elicits a response in the neuron being examined. At the level of the retinal output and thalamus, visual neurons respond to spots of light. The receptive fields of retinal ganglion cells or lateral geniculate neurons are excited or inhibited by light going on or off in the center of the retinal area they respond to.

At the level of the cortex, the responses become more complex^[Each V1 neuron has two receptive fields, one per each eye. V1 neurons can be categorised into two types depending on the shape of their receptive fields: simple and complex. Simple and complex are not categorical but spectral. Simple V1 neurons have an ON receptive region where the neuron will respond to brighter stimuli over grey background and an OFF region where the neuron responds to darker stimuli. In simple neurons these fields are separated. In complex V1 neurons the ON and OFF regions are superimposed. V1 neurons show selectivity over orientation, spatial and temporal frequency, direction of motion, disparity (distance), and color]. However typically the receptive fields of cortical neurons serving foveal vision in the primary visual cortex generally measure less than a degree of visual angle, and a few degrees for peripheral vision. 

In higher-order extrastriate cortical areas, receptive fields often cover a substantial fraction of the entire visual field (which extends about 180 degrees horizontally and 130 degrees vertically). Topography is less apparent in the higher-order regions. 

Up to the level of primary visual cortex, the organization of the visual system is hierarchical in the sense that lower-order stations lead anatomically and functionally to higher-order ones, albeit with modulation and feedback at each stage. Beyond these initial levels, rationalizing the organization of the visual system in terms of lower-order neurons shaping the response properties of higher-order neurons becomes increasingly difficult. The higher order of the nerve cells in the system, the less they depend on visual input, and the more they are influenced by information that is not strictly visual. 

## Visual perception

>**Measuring perception**
>
>Perceptual consequences of stimuli are subjective and can't be measured in any direct way. However they can be reported in terms of thresholds, least discernible differences, or other paradigms in which subjects state whether a percept is brighter or darker, larger or smaller, slower or faster...Such evaluations of perceptual responses are called psychophysics. 
>
>In practice, there are only a limited number of ways to assess perception in relation to physical stimuli. One measurement is to ascertain the least energetic stimulus that elicits a perceptual response. By varying the amount of energy delivered, a psychophysical function can be obtained that defines the stimulus threshold value. Another measurement is to measure how much psychical change is needed to generate a perceptual change. The resulting function is called difference threshold functions. The Weber-Fechner law: the ability to notice a difference is determined by a fixed proportion of the stimulus intensity, not an absolute difference. Another approach is called magnitude scaling, in which subjects order percepts along an ordinal scale that covers the full range of a perceptual quality. Steven's law: perceptual magnitude is a power function of stimuli's physical traits. Finally, reaction time can be useful because of the assumption that more complex neural processing takes longer. 

The primary visual qualities that describe visual perception are lightness, brightness, color, form, depth, and motion. 

### Lightness and brightness

Lightness refers to the appearance of a surface such as a piece of paper. Brightness refers to the appearance of a light source such as the sun. Vision is impossible without these, unless some other qualities such as color which are expendable. The physical correlate of brightness is luminance, however the relationship between luminance and lightness/brightness is puzzling. 

Perceptions of lightness/brightness fail to be directly proportional to luminance. E.g. simultaneous lightness/brightness contrast. 

The sources of luminance values are not specified in retinal images. Retinal luminance is determined by three basic aspects of the physical world: the illumination of objects, the reflectance of object surfaces, and the transmittance of the space between the objects and the observer. Difference combinations of these can give rise to the same value of luminance. There is no logical or direct way to generate a particular retinal luminance value. Vision system has evolved to solve the inverse optics problem by interpreting lightness/brightness according to past experience with the success or failure of behavior in response to different combinations of the physical factors. In this framework, lightness/brightness perceptions would correspond to the relative frequency with which different possible combinations have proved to be the source of the same or similar stimuli. Today's neuroscientists propose the idea that vision and the neural connections that underlie it depend entirely on trial-and-error experience. In this conception, the lightness/brightness values seen by the observer accord with the behavioral significance of stimuli rather than physical intensities of light. 

### Color

Color is the perceptual category generated by the distribution of light across the visible spectrum, the relative amounts of light energy at different wavelengths. Perception of color consists of three qualities: hue, saturation, and color brightness. These three qualities describe a color space. 

In humans, seeing color is based on the different absorption properties of three different cone types with different photopigments (cone opsins), so human vision is trichromats. A common disorder of human color perception arises from a genetic defect in one or more of the three cone types. 

Explanations of color vision based on retinal output from the three human cone types have been inadequate in much the same way that retinal output determined by luminance does not adequately explain the lightness/brightness perception. Just like lightness/brightness, the color we see is strongly influenced by the rest of the scene. E.g. color contrast and color constancy. 

Contextual color perception led to a debate about how global information about the spectral context in scenes is integrated with local spectral information to produce color percepts. The answer again may be that the colors we see are determined empirically to meet the challenge presented by the inherent ambiguity of light stimuli. 

Extrastriate area V4 is especially important in color processing. Studies on people suffering from cerebral achromatopsia have been informative. These patients lose ability to see the world in color while other aspects of vision are intact, following lesions over an extensive region of the ventral occipital cortex that includes V4. Thus whereas V4 is important to color vision, a number of related extrastriate areas probably participate as well. 

### Form 

Perceptions of form entail simple geometrical characteristics such as the length of lines, their apparent orientation, and the angles they make as they interact other lines. 

Perception of form again does not correspond to physical reality. E.g. variation of perceived length, geometrical illusions. 

Active area in V1 tracked the perceived size rather than the actual size in retinal images (Murray et al 2006). 

>**The inverse problem**
>
>A fundamental problem is that images on the retina cannot uniquely specify the physical objects in a scene, because retinal images are only two-dimensional while the physical world is three-dimensional (projection on the retina can have unlimited different physical origins). 
>
>Vision scientists have long proposed that to solve the inverse problem, the visual system might disambiguate images with an empirical boost (past experience) that would help out their interpretation. Recently vision scientists proposed the possibility that percepts may be generated entirely on the basis of empirical success or failure of visual experience in the pasts of both the species and the individual. If this were true, the purpose of visual processing would essentially be to determine relative probabilities of inherently uncertain stimuli, rather than representing the features of the retinal projection. 

#### Distance and depth

Depth is the perception of a three-dimensional world from two-dimensional retinal images. Some aspects of depth are derived from info in the view of one eye alone, but other aspects are apparent only when both eyes are used. Thus depth is usually discussed in its monocular and binocular components. 

Monocular depth perception largely depends on associations learned from experience with the arrangement of objects in space. E.g. occlusion, motion parallax, relationship between size and distance.

Binocular depth perception aka stereopsis arises from the fact that pupils of the eyes are separated horizontally across the face by some distance. Human binocular overlap is about 140 degrees whereas animals with laterally placed eyes have only about 15. Many neurons in both the primary and extrastriate visual cortex of experimental animals have receptive fields that are tuned to specific retinal disparities (prefer one eye or the other?). 

Although we normally view objects with both eyes, the perceived image of the nearby world is a unified one that seems to have been generated from one eye in the middle of the face (cyclopean fusion). How are the two views of each eye conjoined to create a single percept having qualities that are not present in the view of either eye alone? Most explanations depend on the fact that inputs from the two eyes converge on cortical neurons in V1. Many neurons in the deeper and more superficial cortical layers (other than layer 4) in V1 of non-human primates are binocularly driven. Cyclopean vision may arise from this conjuction of right-eye and left-eye inputs at the level of common target cells in the visual cortex. 

However the idea of seeing a cyclopean image by virtue of binocular neurons is incosistent with other evidence such as binocular rivalry. Binocular rivalry refers to the fact that when a particular stimulus pattern is presented to one eye and a strongly discordant pattern is presented to the other eye, the same region of visual space is perceived to be alternately occupied by each pattern but rarely by both. If info is simply unified in the visual cortex the observer would presumably see an integration of two patterns. Other studies have shown that the percepts themselves can be the source of competition. Therefore there have been no consensus about the basis of binocular fusion and rivalry. 

### Motion

Motion is the subjective experience elicited when a sequence of different but related images is presented to the retina over a brief span of time. Motion percepts have two components: a perception of speed and a perception of direction. The middle temporal (MT) and the middle superior temporal (MST) regions are associated with motion processing. 

The role of MT and MST in motion perception is first shown in monkey experiments. Single-neuron recorded activities in MT are associated with the direction of perceived motion. Moreover, microstimulation of neurons in MT increased the probability that the monkeys would move their eyes in the direction of stimuli. Further support comes from a "motion-blind" patient who suffered from a lesion in the motion-sensitive areas of the temporal cortex. 

Because the movement of objects in three-dimensional space is projected onto the two-dimensional retinal surface, the changes in position in physical terms are always uncertain with respect to the possible physical sources that have given rise to a retinal image sequence. The challenge of explaining how the visual system generates quite definite perceptions of speed and direction in response to such stimuli is called the aperture problem. 

Another problem is the apparent motion, the sense of realistic motion generated from a series of static images. A number of different regions tracks apparent motion perception including the motion-sensitive areas in the temporal lobes. 

A final puzzle is motion aftereffects. A usual explanation is that prolonged exposure to a direction of motion causes the motion-activated neurons to adapt, such that when motion stimulus is removed, the nonadapted neurons involved in motion detection in other directions are relatively more active, leading to the illusion of opposite motion. 

### Object recognition

Recognizing objects relies on perceiving the fundamental qualities that characterize vision (brightness, contrast, color, etc.) and associating the basic qualities with additional nonvisual information that identifies the stimulus as objects. For example, an animal can associate the redness of a fruit with ripeness. Recognizing objects is not a task that should be thought of as carried out by the visual system: visual processing triggers associations in other brain regions that lead to object recognition. 

Recognition of objects triggered by visual processing involves the ventral stream that eventually leads to the temporal lobe. Object recognition is supported by different areas in the temporal lobe that have preferences for object categories. For example, the fusiform face area is specialised for faces. Other known regions have preferences for animals, inanimate objects, natural scenes, and words (visual word form area in left fusiform gyrus). However it unlikely that every category of objects has a dedicated area. 

Studies in non-human primates: neurons in the ITC of rhesus monkeys are specifically responsive to faces, and some of these neurons are view-selective (portraits or profiles). Stimulation of these areas biases monkeys to respond better to faces presented in a noisy background. 

Human single-neuron recording shows some neurons in the temporal lobe that are specifically responsive to faces of particular interest to the patient. Sometimes these neurons also respond to the person's voice, suggesting that face-sensitive neurons are part of a network that integrates characteristics from multiple modalities. In line with this, other areas such as the frontal lobes, the superior temporal sulcus, the extrastriate regions of the occipital lobes, and the amygdala are also shown to be involved in face recognition in some ways. 

Faces are identified by comparison with a standard or norm: humans are better at recognising faces with extreme features than less distinctive faces. Monkey ITC neurons respond more strongly to caricatures of human faces than to actual human faces. 

These complex response properties may be based on a columnar anatomical arrangement similar to the primary visual cortex. Each column represents different arrangements of complex features making up an object, the overall spatial pattern of neuronal activity representing the object in view: object recognition depends on populations of neurons rather than on the specific output of one or a few cells that are selective for a particular object. Rough images of what subjects see can be reconstructed from fMRI activity while they view natural scenes or movies. 

Object recognition algorithms are generally thought of as filters that highlight the most important or salient aspects of objects of interest. These filters range in specificity from contrast boundaries to specific features such as the eyes or mouth. We indeed spend more time looking at salient features than looking at other aspects of a scene. However important objects such as faces also tend to be processed more holistically than less significant or frequent objects. 

### Perceiving remembered images

When visual scenes are brought to mind, many regions of the visual cortex are activated, with some evidence of retinotopic organization in the primary visual cortex. Object recognition regions in the temporal lobe are also activated. These observations are consistent with the idea that stored information is located or at least reactivated in the regions of the brain that processed that information in the first place - an important issue in memory. 