---
layout: post
title: (Ryskin & Nieuwland 2023) Prediction during language comprehension - what is next?
date: 2024-03-07 14:00
author: Yiling Huo
tags: ['prediction in language comprehension', 'review', 'cognitive control']
journal: Trends in Cognitive Sciences
link: https://doi.org/10.1016/j.tics.2023.08.003

star: ['prediction', 'prediction and domain general']
---

- Review studies showing that listeners and readers use all manner of contextual information to generate multifaceted predictions about upcoming input. 
- The nature of these predictions may vary between individuals owing to differences in language experience, among other factors. 
- Three unsolved questions: 
    - Is prediction essential to language processing or an optional strategy?
    - Are predictions generated from within the language system or by domain-general processes?
    - What is the relationship between prediction and memory?
    - Does prediction in comprehension require simulation via the production system?

## Why predict?

Everyday conversations are very fast: despite the typical 2-3 words/s speech rate, interlocutors start responding within a quarter of a second after the other finishes, if not sooner. An increasingly popular hypothesis is that people are generally able to keep up with language input by predicting what comes next - by activating the meaning and potentially other aspects of words ahead of time. But the underlying cognitive architecture and mechanism is still unclear.

Deep learning and comp modeling suggest that predicting the next word (or other linguistic units) is what makes models successful in learning human-like language or replicating behavioural and neuroimaging results. Prediction has also been a highly productive explanatory framework across domains of cognitive science (e.g. predictive coding in vision). 

> Predictive coding
>
> 1. Hierarchical organization: sensory inputs are represented at the lowest levels, whereas more abstract information (e.g. word meanings) is represented at higher levels of the hierarchy.
> 2. Top-down predictions are transmitted from higher levels to lower levels of the hierarchy: each level predicts the responses in the level immediately below via feedback connections.
> 3. Bottom-up prediction errors travel from lower levels to higher levels of the hierarchy: each level transmits the discrepancy between the predicted response and the estimated actual response to the level immediately above it via feed forward connections.
> 4. Prediction errors are used to update the response at each level and generate the next prediction, thus allowing the mind to process/infer the current input and continuously adapt to its environment.
> 5. Predictions and errors are carried by distinct populations of functional units.
> 6. Bayesian inference and precision-weighting: the predictive coding algorithm approximates Bayesian inference. 

However, prediction at the computational level need not be implemented by a mechanism with an explicitly predictive objective. Models with different objective functions (e.g. incremental word recognition, homeostasis) can also account for some aspects of predictive behavior in humans ([citation](https://link.springer.com/article/10.3758/s13423-021-01924-x) and [citation](https://doi.org/10.1016/j.brainres.2021.147578)). 